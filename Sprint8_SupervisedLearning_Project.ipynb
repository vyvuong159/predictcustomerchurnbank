{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project description\n",
    "\n",
    "- Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones.\n",
    "- We need to predict whether a customer will leave the bank soon. You have the data on clients’ past behavior and termination of contracts with the bank.\n",
    "- Build a model with the maximum possible F1 score. To pass the project, you need an F1 score of at least 0.59. Check the F1 for the test set.\n",
    "- Additionally, measure the AUC-ROC metric and compare it with the F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research question:\n",
    "***Whether a customer will leave the bank soon?***\n",
    "\n",
    "## Model type: CLASSIFICATION\n",
    "Because we want to classify if a customer belongs to \"leave\" or \"not leave\" categories\n",
    "\n",
    "## Potential models:\n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier\n",
    "- Logistic Regression\n",
    "\n",
    "## Model performance metrics:\n",
    "- F1 score\n",
    "- AUC-ROC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Open the data file and study the general information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and look at basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pd.read_csv('https://code.s3.yandex.net/datasets/Churn.csv')\n",
    "churn.info()\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions for Step 1\n",
    "- There are 10000 observations, describing the info for each customer of Beta Bank.\n",
    "- The identifier variables include: RowNumber, Customerid and Surname - these variables are not necessary for model building \n",
    "- The features that are crucial for model building include: \n",
    "    - CreditScore (integer): credit score\n",
    "    - Geography (string): country of residence\n",
    "    - Gender (string): gender\n",
    "    - Age (integer): age in years\n",
    "    - Tenure (float): period of maturation for a customer’s fixed deposit (years)\n",
    "    - Balance (float): account balance\n",
    "    - NumOfProducts (integer): number of banking products used by the customer\n",
    "    - HasCrCard (integer): customer has a credit card\n",
    "    - IsActiveMember (integer): customer’s activeness\n",
    "    - EstimatedSalary (float): estimated salary\n",
    "- The target is the **Exited** variable: сustomer has left (left - 1, Not left - 0).\n",
    "- Missing values only occur under the 'Tenure' variable\n",
    "- We need to create dummy variables for categorical variables, \"Geography\" and \"Gender\"\n",
    "### We need to preprocess the data in Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Prepare the data for training the model\n",
    "## Preprocess the data\n",
    "Based on our initial investigation in Step 1, we need to take the following steps to prepare the data:\n",
    "- Make all column names lowercase for faster typing \n",
    "- Remove unneccesary variables (RowNumber, Customerid and Surname)\n",
    "- Investigate duplicated rows\n",
    "\n",
    "## Prepare the features\n",
    "- Create dummy variables using end hot code using one-hot encoding\n",
    "- Scale the numeric features \n",
    "\n",
    "## Deal with missing values\n",
    "- Impute missing values using mode because the variable is integer.\n",
    "\n",
    "## Resampling the data to fix the imbalance (will do together with Step 3)\n",
    "- Investigate the balance of classes\n",
    "- Train the model without taking into account the imbalance. Briefly describe your findings.\n",
    "- Improve the quality of the model. Make sure you use at least two approaches to fixing class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all column names lowercase for faster typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownumber</th>\n",
       "      <th>customerid</th>\n",
       "      <th>surname</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rownumber  customerid   surname  creditscore geography  gender  age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   tenure    balance  numofproducts  hascrcard  isactivemember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   estimatedsalary  exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.columns = map(str.lower, churn.columns)\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate if there are any duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rownumber</th>\n",
       "      <th>customerid</th>\n",
       "      <th>surname</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rownumber, customerid, surname, creditscore, geography, gender, age, tenure, balance, numofproducts, hascrcard, isactivemember, estimatedsalary, exited]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn[churn.duplicated()]\n",
    "#No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unneccesary variables (RowNumber, Customerid and Surname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "creditscore        10000 non-null int64\n",
      "geography          10000 non-null object\n",
      "gender             10000 non-null object\n",
      "age                10000 non-null int64\n",
      "tenure             9091 non-null float64\n",
      "balance            10000 non-null float64\n",
      "numofproducts      10000 non-null int64\n",
      "hascrcard          10000 non-null int64\n",
      "isactivemember     10000 non-null int64\n",
      "estimatedsalary    10000 non-null float64\n",
      "exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "churn_df = churn.iloc[:,3:]\n",
    "churn_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Prepare the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate potential categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Spain', 'Germany'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df['geography'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Female', 'Male'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df['gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore  age  tenure    balance  numofproducts  hascrcard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   isactivemember  estimatedsalary  exited  geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_ohe = pd.get_dummies(churn_df, drop_first=True)\n",
    "churn_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creditscore          0.0000\n",
       "age                  0.0000\n",
       "tenure               0.0909\n",
       "balance              0.0000\n",
       "numofproducts        0.0000\n",
       "hascrcard            0.0000\n",
       "isactivemember       0.0000\n",
       "estimatedsalary      0.0000\n",
       "exited               0.0000\n",
       "geography_Germany    0.0000\n",
       "geography_Spain      0.0000\n",
       "gender_Male          0.0000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_ohe.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values occur in the **tenure** variable, accounting for 9% of the whole observation. We are going impute missing values with the mode (because the value in this variable is integer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values with mode value because tenure is inherently a integer variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0., nan])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_ohe['tenure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_ohe_imputena = churn_ohe\n",
    "churn_ohe_imputena['tenure'] = churn_ohe_imputena['tenure'].fillna(churn_ohe_imputena['tenure'].mode()[0])\n",
    "churn_ohe_imputena['tenure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(churn_ohe_imputena)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So now the new dataframe (whose missing values are imputed) is churn_ohe_imputena (10000 observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the numeric features\n",
    "- Look at the range of the numeric variables first to see if there are any anomalies\n",
    "- Scale them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.634300</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>0.250900</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.989725</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0.433553</td>\n",
       "      <td>0.431698</td>\n",
       "      <td>0.497932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        creditscore           age        tenure        balance  numofproducts  \\\n",
       "count  10000.000000  10000.000000  10000.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800      4.634300   76485.889288       1.530200   \n",
       "std       96.653299     10.487806      2.989725   62397.405202       0.581654   \n",
       "min      350.000000     18.000000      0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000      2.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000      4.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000      7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000     10.000000  250898.090000       4.000000   \n",
       "\n",
       "         hascrcard  isactivemember  estimatedsalary        exited  \\\n",
       "count  10000.00000    10000.000000     10000.000000  10000.000000   \n",
       "mean       0.70550        0.515100    100090.239881      0.203700   \n",
       "std        0.45584        0.499797     57510.492818      0.402769   \n",
       "min        0.00000        0.000000        11.580000      0.000000   \n",
       "25%        0.00000        0.000000     51002.110000      0.000000   \n",
       "50%        1.00000        1.000000    100193.915000      0.000000   \n",
       "75%        1.00000        1.000000    149388.247500      0.000000   \n",
       "max        1.00000        1.000000    199992.480000      1.000000   \n",
       "\n",
       "       geography_Germany  geography_Spain   gender_Male  \n",
       "count       10000.000000     10000.000000  10000.000000  \n",
       "mean            0.250900         0.247700      0.545700  \n",
       "std             0.433553         0.431698      0.497932  \n",
       "min             0.000000         0.000000      0.000000  \n",
       "25%             0.000000         0.000000      0.000000  \n",
       "50%             0.000000         0.000000      1.000000  \n",
       "75%             1.000000         0.000000      1.000000  \n",
       "max             1.000000         1.000000      1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_ohe.describe() #nothing abnormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no obvious anomalies in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-0.881162</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.215657</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.125812</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.215657</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-0.881162</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore       age    tenure   balance  numofproducts  hascrcard  \\\n",
       "0    -0.326221  0.293517 -0.881162 -1.225848              1          1   \n",
       "1    -0.440036  0.198164 -1.215657  0.117350              1          0   \n",
       "2    -1.536794  0.293517  1.125812  1.333053              3          1   \n",
       "3     0.501521  0.007457 -1.215657 -1.225848              2          0   \n",
       "4     2.063884  0.388871 -0.881162  0.785728              1          1   \n",
       "\n",
       "   isactivemember  estimatedsalary  exited  geography_Germany  \\\n",
       "0               1         0.021886       1                  0   \n",
       "1               1         0.216534       0                  0   \n",
       "2               0         0.240687       1                  0   \n",
       "3               0        -0.108918       0                  0   \n",
       "4               1        -0.365276       0                  0   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save numeric variables \n",
    "churn_numeric = ['creditscore', 'age', 'tenure', 'balance', 'estimatedsalary']\n",
    "\n",
    "#Save the scaler \n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit the scaler into the data and transform it\n",
    "churn_ohe_imputena[churn_numeric] = scaler.fit_transform(churn_ohe_imputena[churn_numeric])\n",
    "\n",
    "churn_ohe_imputena.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the balance of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2037"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(churn_ohe_imputena['exited'] == 1)/len(churn_ohe_imputena['exited'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive class only accounts for 20% of the whole dataset --> **IMBALANCE** --> Need to upsampling the positive class or downsampling the negative class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build the model (without and with fixing target imbalance)\n",
    "- Split the source data into a training set, a validation set, and a test set with the ratio 3:1:1\n",
    "- Fit different models that are appropriate for classification problem, investigate the quality of different models by changing hyperparameters\n",
    "- Try with the unbalanced data, the upsampled and downsampled data too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Split the source data into a training set, a validation set, and a test set with the ratio 3:1:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the feature and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = churn_ohe_imputena.drop('exited', axis=1)\n",
    "target = churn_ohe_imputena['exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the source data into a training set, a validation set, and a test set with the ratio 3:1:!\n",
    "Use train_split_test twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First split the data into 2 sets: 60% for train and 40% for test (actually for test and validate)\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(feature, target, \n",
    "                                                                           test_size=0.4, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second split the above data into further 2 sets of test and validate, each has 50% of data\n",
    "feature_val, feature_test, target_val, target_test = train_test_split(feature_test, target_test,\n",
    "                                                                     test_size=0.5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if each dataset has the correct proportion (60%, 20%, 20% of the total number of observations of the source data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "for data in [target_train, target_val, target_test]:\n",
    "    print(round(len(data)/len(target), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - Build the model without fixing target imbalance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Fit different models that are appropriate for classification problem, investigate the quality of different models by changing hyperparameters\n",
    "\n",
    "The three appropriate models for this classification probelm are:\n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier\n",
    "- Logistic Regression\n",
    "\n",
    "To pass the project, you need an F1 score of at least 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DecisionTreeClassfier model\n",
    "- Create a loop to test different hyperparameters (max_depth): test from 1-50\n",
    "- Then choose the best model based on F1 score of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 | F1 score - Training: 0.0 - Validate: 0.0\n",
      "max_depth: 2 | F1 score - Training: 0.5019493177387914 - Validate: 0.5354107648725214\n",
      "max_depth: 3 | F1 score - Training: 0.3835616438356165 - Validate: 0.38113207547169814\n",
      "max_depth: 4 | F1 score - Training: 0.5254054054054054 - Validate: 0.5318818040435458\n",
      "max_depth: 5 | F1 score - Training: 0.5482456140350876 - Validate: 0.5339805825242718\n",
      "max_depth: 6 | F1 score - Training: 0.5909568874868558 - Validate: 0.5727554179566563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 7 | F1 score - Training: 0.6268806419257774 - Validate: 0.5775862068965517\n",
      "max_depth: 8 | F1 score - Training: 0.6740172579098754 - Validate: 0.6008344923504868\n",
      "max_depth: 9 | F1 score - Training: 0.7045565899069084 - Validate: 0.5580736543909348\n",
      "max_depth: 10 | F1 score - Training: 0.7498795180722891 - Validate: 0.5594405594405594\n",
      "max_depth: 11 | F1 score - Training: 0.807832422586521 - Validate: 0.5387647831800263\n",
      "max_depth: 12 | F1 score - Training: 0.8531150522964985 - Validate: 0.5065963060686016\n",
      "max_depth: 13 | F1 score - Training: 0.8972209969122188 - Validate: 0.5168831168831168\n",
      "max_depth: 14 | F1 score - Training: 0.928695652173913 - Validate: 0.5083014048531289\n",
      "max_depth: 15 | F1 score - Training: 0.9556313993174061 - Validate: 0.5030978934324659\n",
      "max_depth: 16 | F1 score - Training: 0.9723521905572098 - Validate: 0.50187265917603\n",
      "max_depth: 17 | F1 score - Training: 0.9852008456659619 - Validate: 0.4975369458128079\n",
      "max_depth: 18 | F1 score - Training: 0.9907016060862215 - Validate: 0.4975247524752475\n",
      "max_depth: 19 | F1 score - Training: 0.9962073324905183 - Validate: 0.4852216748768473\n",
      "max_depth: 20 | F1 score - Training: 0.9974747474747475 - Validate: 0.49261083743842365\n",
      "max_depth: 21 | F1 score - Training: 0.9983179142136249 - Validate: 0.4968944099378882\n",
      "max_depth: 22 | F1 score - Training: 0.9987389659520807 - Validate: 0.49572649572649574\n",
      "max_depth: 23 | F1 score - Training: 0.9991596638655461 - Validate: 0.4932515337423312\n",
      "max_depth: 24 | F1 score - Training: 0.9991596638655461 - Validate: 0.5036496350364965\n",
      "max_depth: 25 | F1 score - Training: 0.9995803608896349 - Validate: 0.4830097087378641\n",
      "max_depth: 26 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 27 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 28 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 29 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 30 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 31 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 32 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 33 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 34 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 35 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 36 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 37 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 38 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 39 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 40 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 41 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 42 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 43 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 44 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 45 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 46 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 47 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 48 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n",
      "max_depth: 49 | F1 score - Training: 1.0 - Validate: 0.5043050430504304\n"
     ]
    }
   ],
   "source": [
    "for depth in range (1,50, 1):\n",
    "    model1 = DecisionTreeClassifier(random_state=12, max_depth=depth)\n",
    "    model1.fit(feature_train, target_train)\n",
    "    prediction_train = model1.predict(feature_train)\n",
    "    prediction_val = model1.predict(feature_val)\n",
    "    print('max_depth: {}'.format(depth),\n",
    "          '| F1 score',\n",
    "          '- Training: {}'.format(f1_score(target_train, prediction_train)),\n",
    "          '- Validate: {}'.format(f1_score(target_val, prediction_val), sep='\\n'))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Investigate why F1 = 0 for max_depth = 1\n",
    "model1 = DecisionTreeClassifier(random_state=12, max_depth=1)\n",
    "model1.fit(feature_train, target_train)\n",
    "prediction_train = model1.predict(feature_train)\n",
    "prediction_val = model1.predict(feature_val)\n",
    "# prediction_val.unqiue()\n",
    "pd.Series(prediction_val).unique() #array([0])\n",
    "\n",
    "#Because When max_depth = 1, the model only predict 0, thus no positive predictions.\n",
    "#F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#precision = TP/(TP+FP) model doesn't predicts positive class at all - precision is 0.\n",
    "\n",
    "#recall = TP/(TP+FN), model doesn't predicts positive class at all - TP is 0 - recall is 0.\n",
    "\n",
    "#So now we are dividing 0/0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree model: max_depth = 8 returned the satisfied F1 score (>= 0.59)\n",
    "We also observed that starting from max_depth = 7, the larger max_depth is, the more the model overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RandomForestClassfier model\n",
    "- Create a loop to iterate through different max_depth values  to find the optimal hyperparameters, set n_estimators=100\n",
    "- Then choose the best model based on F1 score of the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first fit a random forest with default parameters to get a baseline idea of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=12, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=12)\n",
    "rf.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pred = rf.predict(feature_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use F1 Score and AUC (Area Under Curve) as the evaluation metric. Our target value is binary so it’s a binary classification problem. F1 score and AUC are good ways for evaluation for this type of problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5236593059936908"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(target_val, target_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This F1 score did not satisfy the requirement, we need to tune the model parameter. Let try different max_depth with n_estimators=100 (by default of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0\n",
      "2 0.1050228310502283\n",
      "3 0.1592920353982301\n",
      "4 0.3488372093023256\n",
      "5 0.4335154826958106\n",
      "6 0.5109983079526227\n",
      "7 0.5439739413680782\n",
      "8 0.5603864734299516\n",
      "9 0.5650793650793652\n",
      "10 0.5830721003134797\n",
      "11 0.5996908809891809\n",
      "12 0.5823170731707317\n",
      "13 0.5871559633027523\n",
      "14 0.5966514459665144\n",
      "15 0.5889387144992526\n",
      "16 0.5964391691394659\n",
      "17 0.5740181268882175\n",
      "18 0.5744360902255639\n",
      "19 0.5967503692762186\n",
      "20 0.5924812030075188\n"
     ]
    }
   ],
   "source": [
    "#Create a loop to iterate through different max_depth values\n",
    "for n in range(1,21,1): \n",
    "    model2 = RandomForestClassifier(max_depth=n, n_estimators=100, random_state=12)\n",
    "    model2.fit(feature_train,target_train)\n",
    "    prediction_val = model2.predict(feature_val)\n",
    "    f1 = f1_score(target_val,prediction_val)\n",
    "    print(n, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model: max_depth = 11 and n_estimators=100 is the best combination, producing F1 score = 0.599"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LogisticRegression model\n",
    "No need to tune the hyperameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LogisticRegression(random_state=12, solver = 'liblinear')\n",
    "model3.fit(feature_train, target_train)\n",
    "prediction_train = model3.predict(feature_train)\n",
    "prediction_val = model3.predict(feature_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score\n",
      "Training set:  0.2900569981000633\n",
      "Validation set:  0.3037037037037037\n"
     ]
    }
   ],
   "source": [
    "print('F1 score')\n",
    "print('Training set: ', f1_score(target_train, prediction_train))\n",
    "print('Validation set: ', f1_score(target_val, prediction_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model: F1 score is too low for both training and validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion for the data whose imbalance has not been fixed:\n",
    "- This data has much more 0 than 1, therefore the model mostly predicts 0 for the new data points. \n",
    "- Model performance:\n",
    "    - Decision Tree and Random Forest model with above mentioned parameters produces the F1 score that meets the minimum requirement of this assignment. However, the F1 score is low. \n",
    "    - Logistic Regression, without tuning any parameter, did not produce the satisfied F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - Build the model with fixing target imbalance \n",
    "2 approaches to fix the imbalance:\n",
    "- Upsampling\n",
    "- Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1. Upsampling the positive class\n",
    "Try a few ratios between positive and negative class\n",
    "- 1:1\n",
    "- 2:3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the function to upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the upsample function for the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio between positive and negative class: **1:1**, repeat = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_upsampled, target_train_upsampled = upsample(feature_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49764963961140707"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the ratio between 1 and 0 - need to be ~50%\n",
    "sum(target_train_upsampled == 1)/len(target_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the models, tune hyperparameters to see if there is any improvement in model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DecisionTreeClassfier model\n",
    "- Create a loop to test different hyperparameters (max_depth): test from 1-50\n",
    "- Then choose the best model based on F1 score of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 - F1 Score 0.4837476099426386\n",
      "max_depth: 2 - F1 Score 0.5116279069767442\n",
      "max_depth: 3 - F1 Score 0.5283757338551859\n",
      "max_depth: 4 - F1 Score 0.5307497893850042\n",
      "max_depth: 5 - F1 Score 0.577490774907749\n",
      "max_depth: 6 - F1 Score 0.5680365296803653\n",
      "max_depth: 7 - F1 Score 0.5782442748091603\n",
      "max_depth: 8 - F1 Score 0.5827686350435625\n",
      "max_depth: 9 - F1 Score 0.5803842264914054\n",
      "max_depth: 10 - F1 Score 0.572\n",
      "max_depth: 11 - F1 Score 0.5683760683760684\n",
      "max_depth: 12 - F1 Score 0.5569060773480662\n",
      "max_depth: 13 - F1 Score 0.552026286966046\n",
      "max_depth: 14 - F1 Score 0.5340782122905029\n",
      "max_depth: 15 - F1 Score 0.5339265850945495\n",
      "max_depth: 16 - F1 Score 0.5291375291375292\n",
      "max_depth: 17 - F1 Score 0.5301204819277109\n",
      "max_depth: 18 - F1 Score 0.5270758122743683\n",
      "max_depth: 19 - F1 Score 0.5320197044334974\n",
      "max_depth: 20 - F1 Score 0.5167701863354037\n",
      "max_depth: 21 - F1 Score 0.5186104218362283\n",
      "max_depth: 22 - F1 Score 0.4987468671679198\n",
      "max_depth: 23 - F1 Score 0.506900878293601\n",
      "max_depth: 24 - F1 Score 0.508816120906801\n",
      "max_depth: 25 - F1 Score 0.5161290322580645\n",
      "max_depth: 26 - F1 Score 0.5161290322580645\n",
      "max_depth: 27 - F1 Score 0.5161290322580645\n",
      "max_depth: 28 - F1 Score 0.5161290322580645\n",
      "max_depth: 29 - F1 Score 0.5161290322580645\n",
      "max_depth: 30 - F1 Score 0.5161290322580645\n",
      "max_depth: 31 - F1 Score 0.5161290322580645\n",
      "max_depth: 32 - F1 Score 0.5161290322580645\n",
      "max_depth: 33 - F1 Score 0.5161290322580645\n",
      "max_depth: 34 - F1 Score 0.5161290322580645\n",
      "max_depth: 35 - F1 Score 0.5161290322580645\n",
      "max_depth: 36 - F1 Score 0.5161290322580645\n",
      "max_depth: 37 - F1 Score 0.5161290322580645\n",
      "max_depth: 38 - F1 Score 0.5161290322580645\n",
      "max_depth: 39 - F1 Score 0.5161290322580645\n",
      "max_depth: 40 - F1 Score 0.5161290322580645\n",
      "max_depth: 41 - F1 Score 0.5161290322580645\n",
      "max_depth: 42 - F1 Score 0.5161290322580645\n",
      "max_depth: 43 - F1 Score 0.5161290322580645\n",
      "max_depth: 44 - F1 Score 0.5161290322580645\n",
      "max_depth: 45 - F1 Score 0.5161290322580645\n",
      "max_depth: 46 - F1 Score 0.5161290322580645\n",
      "max_depth: 47 - F1 Score 0.5161290322580645\n",
      "max_depth: 48 - F1 Score 0.5161290322580645\n",
      "max_depth: 49 - F1 Score 0.5161290322580645\n"
     ]
    }
   ],
   "source": [
    "for depth in range (1,50, 1):\n",
    "    model1 = DecisionTreeClassifier(random_state=12, max_depth=depth)\n",
    "    model1.fit(feature_train_upsampled, target_train_upsampled)\n",
    "    prediction_train = model1.predict(feature_train_upsampled)\n",
    "    prediction_val = model1.predict(feature_val)\n",
    "    print('max_depth:', depth, '- F1 Score', f1_score(target_val, prediction_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- Now F1 score for lower max_depths (1-3) improved\n",
    "- However in general F1 score did not improve compared to the unbalanced data\n",
    "- There is not any max_depth that can produce F1 score that satisfies the requirement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RandomForestClassfier model\n",
    "- Create a loop to find the optimal hyperparameters\n",
    "- Then choose the best model based on F1 score of the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first fit a random forest with default parameters to get a baseline idea of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5825242718446602"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=12)\n",
    "rf.fit(feature_train_upsampled, target_train_upsampled)\n",
    "target_pred = rf.predict(feature_val)\n",
    "f1 = f1_score(target_val, target_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This F1 score, though improved comapred to the unbalanced data, did not satisfy the requirement, we need to tune the model parameter. Let try different max_depth with n_estimators=100 (by default of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.524074074074074\n",
      "2 0.5512572533849128\n",
      "3 0.5912334352701325\n",
      "4 0.5939393939393939\n",
      "5 0.6043165467625898\n",
      "6 0.6230529595015577\n",
      "7 0.6251319957761352\n",
      "8 0.64340239912759\n",
      "9 0.6388583973655325\n",
      "10 0.6468571428571428\n",
      "11 0.6526806526806528\n",
      "12 0.6577992744860944\n",
      "13 0.6517412935323382\n",
      "14 0.6480304955527318\n",
      "15 0.6336375488917863\n",
      "16 0.6380208333333333\n",
      "17 0.6335078534031414\n",
      "18 0.6265060240963854\n",
      "19 0.6352624495289367\n",
      "20 0.6374501992031872\n"
     ]
    }
   ],
   "source": [
    "#Create a loop to iterate through different max_depth values\n",
    "for n in range(1,21,1): \n",
    "    model2 = RandomForestClassifier(max_depth=n, n_estimators=100, random_state=12)\n",
    "    model2.fit(feature_train_upsampled, target_train_upsampled)\n",
    "    prediction_val = model2.predict(feature_val)\n",
    "    f1 = f1_score(target_val,prediction_val)\n",
    "    print(n, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- F1 score of Random Forest of the upsampled data (1:1) improved a lot comapred to the unbalanced data\n",
    "- Random Forest model with max_depth = 12 and n_estimators=100 is the best combination, producing F1 score = 0.657. Other max_depths satisfying the requirement are: range(3, 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LogisticRegression model\n",
    "No need to tune the hyperameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LogisticRegression(random_state=12, solver = 'liblinear')\n",
    "model3.fit(feature_train_upsampled, target_train_upsampled)\n",
    "prediction_train = model3.predict(feature_train_upsampled)\n",
    "prediction_val = model3.predict(feature_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score\n",
      "Training set:  0.7054329371816638\n",
      "Validation set:  0.5215859030837003\n"
     ]
    }
   ],
   "source": [
    "print('F1 score')\n",
    "print('Training set: ', f1_score(target_train_upsampled, prediction_train))\n",
    "print('Validation set: ', f1_score(target_val, prediction_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- F1 score of training and validation sets of the upsampled data improved comapred to the unbalanced data\n",
    "- However, the F1 score of the validation data still did not satisfy the requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio between positive and negative class: **2:3**, repeat = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_upsampled, target_train_upsampled = upsample(feature_train, target_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4262705798138869"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the ratio between 1 and 0 - need to be ~50%\n",
    "sum(target_train_upsampled == 1)/len(target_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the models, tune hyperparameters to see if there is any improvement in model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DecisionTreeClassfier model\n",
    "- Create a loop to test different hyperparameters (max_depth): test from 1-50\n",
    "- Then choose the best model based on F1 score of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 - F1 Score 0.4837476099426386\n",
      "max_depth: 2 - F1 Score 0.5116279069767442\n",
      "max_depth: 3 - F1 Score 0.5598923283983849\n",
      "max_depth: 4 - F1 Score 0.5625\n",
      "max_depth: 5 - F1 Score 0.5974304068522485\n",
      "max_depth: 6 - F1 Score 0.5984598459845983\n",
      "max_depth: 7 - F1 Score 0.596153846153846\n",
      "max_depth: 8 - F1 Score 0.5858170606372045\n",
      "max_depth: 9 - F1 Score 0.586864406779661\n",
      "max_depth: 10 - F1 Score 0.5816216216216216\n",
      "max_depth: 11 - F1 Score 0.5711229946524062\n",
      "max_depth: 12 - F1 Score 0.5570776255707763\n",
      "max_depth: 13 - F1 Score 0.5509259259259259\n",
      "max_depth: 14 - F1 Score 0.5360360360360361\n",
      "max_depth: 15 - F1 Score 0.5393518518518519\n",
      "max_depth: 16 - F1 Score 0.5300613496932515\n",
      "max_depth: 17 - F1 Score 0.5291262135922329\n",
      "max_depth: 18 - F1 Score 0.516209476309227\n",
      "max_depth: 19 - F1 Score 0.5248756218905473\n",
      "max_depth: 20 - F1 Score 0.5238095238095237\n",
      "max_depth: 21 - F1 Score 0.517948717948718\n",
      "max_depth: 22 - F1 Score 0.5252525252525252\n",
      "max_depth: 23 - F1 Score 0.5126903553299492\n",
      "max_depth: 24 - F1 Score 0.5272496831432193\n",
      "max_depth: 25 - F1 Score 0.5170239596469105\n",
      "max_depth: 26 - F1 Score 0.5170239596469105\n",
      "max_depth: 27 - F1 Score 0.5170239596469105\n",
      "max_depth: 28 - F1 Score 0.5170239596469105\n",
      "max_depth: 29 - F1 Score 0.5170239596469105\n",
      "max_depth: 30 - F1 Score 0.5170239596469105\n",
      "max_depth: 31 - F1 Score 0.5170239596469105\n",
      "max_depth: 32 - F1 Score 0.5170239596469105\n",
      "max_depth: 33 - F1 Score 0.5170239596469105\n",
      "max_depth: 34 - F1 Score 0.5170239596469105\n",
      "max_depth: 35 - F1 Score 0.5170239596469105\n",
      "max_depth: 36 - F1 Score 0.5170239596469105\n",
      "max_depth: 37 - F1 Score 0.5170239596469105\n",
      "max_depth: 38 - F1 Score 0.5170239596469105\n",
      "max_depth: 39 - F1 Score 0.5170239596469105\n",
      "max_depth: 40 - F1 Score 0.5170239596469105\n",
      "max_depth: 41 - F1 Score 0.5170239596469105\n",
      "max_depth: 42 - F1 Score 0.5170239596469105\n",
      "max_depth: 43 - F1 Score 0.5170239596469105\n",
      "max_depth: 44 - F1 Score 0.5170239596469105\n",
      "max_depth: 45 - F1 Score 0.5170239596469105\n",
      "max_depth: 46 - F1 Score 0.5170239596469105\n",
      "max_depth: 47 - F1 Score 0.5170239596469105\n",
      "max_depth: 48 - F1 Score 0.5170239596469105\n",
      "max_depth: 49 - F1 Score 0.5170239596469105\n"
     ]
    }
   ],
   "source": [
    "for depth in range (1,50, 1):\n",
    "    model1 = DecisionTreeClassifier(random_state=12, max_depth=depth)\n",
    "    model1.fit(feature_train_upsampled, target_train_upsampled)\n",
    "    prediction_train = model1.predict(feature_train_upsampled)\n",
    "    prediction_val = model1.predict(feature_val)\n",
    "    print('max_depth:', depth, '- F1 Score', f1_score(target_val, prediction_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- Now F1 score of Decision Tree of upsampled data for lower max_depths (1-3) improved compared to the unbalanced data\n",
    "- F1 score for the remaining max_depths did not improve much compared to the unbalanced data\n",
    "- max_depth that can produce F1 score that satisfies the requirement are: 5, 6, 7, 8, 9 - the highest F1 score is at 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RandomForestClassfier model\n",
    "- Create a loop to find the optimal hyperparameter (combining max_Depth and n_estimators).\n",
    "- Then choose the best model based on F1 score of the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first fit a random forest with default parameters to get a baseline idea of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5880758807588076"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=12)\n",
    "rf.fit(feature_train_upsampled, target_train_upsampled)\n",
    "target_pred = rf.predict(feature_val)\n",
    "f1 = f1_score(target_val, target_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This F1 score satisfied the requirement, we will tune the model parameter to see if we can improve F1 score. Let try different max_depth with n_estimators=100 (by default of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.4193011647254576\n",
      "2 0.5897771952817824\n",
      "3 0.5788849347568208\n",
      "4 0.5992865636147443\n",
      "5 0.6124852767962308\n",
      "6 0.6252983293556086\n",
      "7 0.6442307692307693\n",
      "8 0.6507177033492823\n",
      "9 0.6514423076923077\n",
      "10 0.6552147239263802\n",
      "11 0.6465408805031447\n",
      "12 0.6445012787723785\n",
      "13 0.6433203631647212\n",
      "14 0.6354166666666666\n",
      "15 0.6321381142098274\n",
      "16 0.6418109187749667\n",
      "17 0.6255033557046981\n",
      "18 0.6243243243243243\n",
      "19 0.6253369272237197\n",
      "20 0.6396761133603238\n"
     ]
    }
   ],
   "source": [
    "#Create a loop to iterate through different max_depth values\n",
    "for n in range(1,21,1): \n",
    "    model2 = RandomForestClassifier(max_depth=n, n_estimators=100, random_state=12)\n",
    "    model2.fit(feature_train_upsampled, target_train_upsampled)\n",
    "    prediction_val = model2.predict(feature_val)\n",
    "    f1 = f1_score(target_val,prediction_val)\n",
    "    print(n, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- F1 score of Random Forest of the balanced data improved a lot comapred to the unbalanced data\n",
    "- Random Forest model with max_depth = 10 and n_estimators=100 is the best combination, producing F1 score = 0.655. Other max_depths satisfying the requirement are: 2, 4, 5, 6, ..., 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LogisticRegression model\n",
    "No need to tune the hyperameter(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to iterate through different \"repeat\" for Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_class(feature, target, repeat):\n",
    "    for i in repeat:\n",
    "        feature_train_upsampled, target_train_upsampled = upsample(feature_train, target_train, i)\n",
    "        model3 = LogisticRegression(random_state=12, solver = 'liblinear')\n",
    "        model3.fit(feature_train_upsampled, target_train_upsampled)\n",
    "        prediction_train = model3.predict(feature_train_upsampled)\n",
    "        prediction_val = model3.predict(feature_val)\n",
    "        print('Repeat = {}'.format(i),\n",
    "              'F1 score',\n",
    "              'Training: {}'.format(f1_score(target_train_upsampled, prediction_train)),\n",
    "              'Validation: {}'.format(f1_score(target_val, prediction_val)), \n",
    "              '-----', sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat = 1\n",
      "F1 score\n",
      "Training: 0.2900569981000633\n",
      "Validation: 0.3037037037037037\n",
      "-----\n",
      "Repeat = 2\n",
      "F1 score\n",
      "Training: 0.5180294565769425\n",
      "Validation: 0.49122807017543857\n",
      "-----\n",
      "Repeat = 3\n",
      "F1 score\n",
      "Training: 0.6215102974828375\n",
      "Validation: 0.5241090146750524\n",
      "-----\n",
      "Repeat = 4\n",
      "F1 score\n",
      "Training: 0.7054329371816638\n",
      "Validation: 0.5215859030837003\n",
      "-----\n",
      "Repeat = 5\n",
      "F1 score\n",
      "Training: 0.7481215289121202\n",
      "Validation: 0.500780031201248\n",
      "-----\n",
      "Repeat = 6\n",
      "F1 score\n",
      "Training: 0.7763297872340426\n",
      "Validation: 0.4777385159010601\n",
      "-----\n",
      "Repeat = 7\n",
      "F1 score\n",
      "Training: 0.8030922637387261\n",
      "Validation: 0.45905867182462934\n",
      "-----\n",
      "Repeat = 8\n",
      "F1 score\n",
      "Training: 0.8205526686416396\n",
      "Validation: 0.44135429262394194\n",
      "-----\n",
      "Repeat = 9\n",
      "F1 score\n",
      "Training: 0.8343858744683592\n",
      "Validation: 0.42956120092378747\n",
      "-----\n",
      "Repeat = 10\n",
      "F1 score\n",
      "Training: 0.8449181340747605\n",
      "Validation: 0.4132231404958677\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "repeat = range(1,11, 1) \n",
    "f1_class(feature_train, target_train, repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- F1 score of training and validation data of the upsampling data improved comapred to the unbalanced data in the logistic regression model\n",
    "- However, the F1 score of the validation data still did not satisfy the requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion for the Upsampling approach\n",
    "- Generally, F1 score improved \n",
    "- Random Forest Classifier seems to be the optimal model with the highest F1 score (also satisfied the requirement of this assignment, which is >= 0.59)\n",
    "\n",
    "Now we try the **downsampling** approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 Downsampling the negative class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the function to downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_downsampled = pd.concat([features_ones] + [features_zeros.sample(frac=fraction, random_state=12)])\n",
    "    target_downsampled = pd.concat([target_ones] + [target_zeros.sample(frac=fraction, random_state=12)])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12)\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the downsample function for the training set with different fractions\n",
    "- The ratio between positive and negative class is 1:1, Fraction = 0.2\n",
    "- The ratio between positive and negative class is 2:3, Fraction = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio between positive and negative class: **1:1**, fraction = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_downsampled, target_train_downsampled = downsample(feature_train, target_train, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5531816070599164"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the ratio between 1 and 0 - need to be ~50%\n",
    "sum(target_train_downsampled == 1)/len(target_train_downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the models, tune hyperparameters to see if there is any improvement in model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DecisionTreeClassfier model\n",
    "- Create a loop to test different hyperparameters (max_depth): test from 1-50\n",
    "- Then choose the best model based on F1 score of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 - F1 Score 0.4837476099426386\n",
      "max_depth: 2 - F1 Score 0.5116279069767442\n",
      "max_depth: 3 - F1 Score 0.5283757338551859\n",
      "max_depth: 4 - F1 Score 0.5262267343485618\n",
      "max_depth: 5 - F1 Score 0.5795768169273229\n",
      "max_depth: 6 - F1 Score 0.557006092254134\n",
      "max_depth: 7 - F1 Score 0.5473501303214596\n",
      "max_depth: 8 - F1 Score 0.551293487957181\n",
      "max_depth: 9 - F1 Score 0.5260416666666667\n",
      "max_depth: 10 - F1 Score 0.5256849315068493\n",
      "max_depth: 11 - F1 Score 0.5153061224489796\n",
      "max_depth: 12 - F1 Score 0.5076923076923077\n",
      "max_depth: 13 - F1 Score 0.4971287940935193\n",
      "max_depth: 14 - F1 Score 0.4853896103896104\n",
      "max_depth: 15 - F1 Score 0.4909688013136289\n",
      "max_depth: 16 - F1 Score 0.48569092395748165\n",
      "max_depth: 17 - F1 Score 0.4850444624090542\n",
      "max_depth: 18 - F1 Score 0.4806451612903225\n",
      "max_depth: 19 - F1 Score 0.47871485943775094\n",
      "max_depth: 20 - F1 Score 0.4862236628849271\n",
      "max_depth: 21 - F1 Score 0.4927302100161551\n",
      "max_depth: 22 - F1 Score 0.4927302100161551\n",
      "max_depth: 23 - F1 Score 0.4927302100161551\n",
      "max_depth: 24 - F1 Score 0.4927302100161551\n",
      "max_depth: 25 - F1 Score 0.4927302100161551\n",
      "max_depth: 26 - F1 Score 0.4927302100161551\n",
      "max_depth: 27 - F1 Score 0.4927302100161551\n",
      "max_depth: 28 - F1 Score 0.4927302100161551\n",
      "max_depth: 29 - F1 Score 0.4927302100161551\n",
      "max_depth: 30 - F1 Score 0.4927302100161551\n",
      "max_depth: 31 - F1 Score 0.4927302100161551\n",
      "max_depth: 32 - F1 Score 0.4927302100161551\n",
      "max_depth: 33 - F1 Score 0.4927302100161551\n",
      "max_depth: 34 - F1 Score 0.4927302100161551\n",
      "max_depth: 35 - F1 Score 0.4927302100161551\n",
      "max_depth: 36 - F1 Score 0.4927302100161551\n",
      "max_depth: 37 - F1 Score 0.4927302100161551\n",
      "max_depth: 38 - F1 Score 0.4927302100161551\n",
      "max_depth: 39 - F1 Score 0.4927302100161551\n",
      "max_depth: 40 - F1 Score 0.4927302100161551\n",
      "max_depth: 41 - F1 Score 0.4927302100161551\n",
      "max_depth: 42 - F1 Score 0.4927302100161551\n",
      "max_depth: 43 - F1 Score 0.4927302100161551\n",
      "max_depth: 44 - F1 Score 0.4927302100161551\n",
      "max_depth: 45 - F1 Score 0.4927302100161551\n",
      "max_depth: 46 - F1 Score 0.4927302100161551\n",
      "max_depth: 47 - F1 Score 0.4927302100161551\n",
      "max_depth: 48 - F1 Score 0.4927302100161551\n",
      "max_depth: 49 - F1 Score 0.4927302100161551\n"
     ]
    }
   ],
   "source": [
    "for depth in range (1,50, 1):\n",
    "    model1 = DecisionTreeClassifier(random_state=12, max_depth=depth)\n",
    "    model1.fit(feature_train_downsampled, target_train_downsampled)\n",
    "    prediction_val = model1.predict(feature_val)\n",
    "    print('max_depth:', depth, '- F1 Score', f1_score(target_val, prediction_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- Now F1 score of lower max_depth (1-3) of the DOWNSAMPLED data improved comapred to the unbalanced data\n",
    "- However in general F1 score did not improve compared to the unbalanced data\n",
    "- There is not any max_depth that can produce F1 score that satisfies the requirement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RandomForestClassfier model\n",
    "- Create a loop to iterate through different max_depths to find the optimal hyperparameters (combining max_Depth and n_estimators).\n",
    "- Then choose the best model based on F1 score of the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first fit a random forest with default parameters to get a baseline idea of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.569060773480663"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=12)\n",
    "rf.fit(feature_train_downsampled, target_train_downsampled)\n",
    "target_pred = rf.predict(feature_val)\n",
    "f1 = f1_score(target_val, target_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This F1 score, though improved comapred to the unbalanced data, did not satisfy the requirement, we need to tune the model parameter. Let try different max_depth with n_estimators=100 (by default of the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.7662863452337136 0.45271122320302637\n",
      "2 0.7765273311897106 0.5252365930599369\n",
      "3 0.7828220858895706 0.5469522240527183\n",
      "4 0.7945544554455446 0.5579831932773109\n",
      "5 0.8054977092877967 0.5674499564838991\n",
      "6 0.8223435531289374 0.5749342681858018\n",
      "7 0.8514934791754313 0.5821428571428572\n",
      "8 0.8751576292559899 0.5814581458145814\n",
      "9 0.9190096516995385 0.5818505338078291\n",
      "10 0.950544844928751 0.5714285714285715\n",
      "11 0.9785443836769037 0.5729632945389436\n",
      "12 0.9920402178466694 0.5853227232537577\n",
      "13 0.9974789915966387 0.574430823117338\n",
      "14 0.9991596638655461 0.5855855855855856\n",
      "15 1.0 0.578853046594982\n",
      "16 1.0 0.5779735682819384\n",
      "17 1.0 0.5772646536412078\n",
      "18 1.0 0.5884444444444444\n",
      "19 1.0 0.583111111111111\n",
      "20 1.0 0.5841495992876224\n"
     ]
    }
   ],
   "source": [
    "#Create a loop to iterate through different max_depth values\n",
    "for n in range(1,21,1): \n",
    "    model2 = RandomForestClassifier(max_depth=n, n_estimators=100, random_state=12)\n",
    "    model2.fit(feature_train_downsampled, target_train_downsampled)\n",
    "    prediction_train = model2.predict(feature_train_downsampled)\n",
    "    prediction_val = model2.predict(feature_val)\n",
    "    f1_train = f1_score(target_train_downsampled, prediction_train)\n",
    "    f1_val = f1_score(target_val,prediction_val)\n",
    "    print(n, f1_train, f1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- F1 score of Random Forest of the DOWNSAMPLED data improved a lot comapred to the unbalanced data, however seems to get worse comapred to the UPSAMPLED data\n",
    "- If rounding up to 2 decimals, models with max_depth = [12, 14, 18] returned F1 score ~ 0.59. \n",
    "- We also see greater discrepancy between training and validation sets starting right from max_depth = 1 --> a warning for model overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LogisticRegression model\n",
    "No need to tune the hyperameter(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to iterate through different \"repeat\" for Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_class(feature, target, fraction):\n",
    "    for i in fraction:\n",
    "        feature_train_downsampled, target_train_downsampled = downsample(feature_train, target_train, i)\n",
    "        model3 = LogisticRegression(random_state=12, solver = 'liblinear')\n",
    "        model3.fit(feature_train_downsampled, target_train_downsampled)\n",
    "        prediction_train = model3.predict(feature_train_downsampled)\n",
    "        prediction_val = model3.predict(feature_val)\n",
    "        print('Repeat = {}'.format(i),\n",
    "              'F1 score',\n",
    "              'Training: {}'.format(f1_score(target_train_downsampled, prediction_train)),\n",
    "              'Validation: {}'.format(f1_score(target_val, prediction_val)), \n",
    "              '-----', sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat = 0.1\n",
      "F1 score\n",
      "Training: 0.8445475638051044\n",
      "Validation: 0.41881298992161264\n",
      "-----\n",
      "Repeat = 0.15000000000000002\n",
      "F1 score\n",
      "Training: 0.79874213836478\n",
      "Validation: 0.47137150466045274\n",
      "-----\n",
      "Repeat = 0.20000000000000004\n",
      "F1 score\n",
      "Training: 0.7422512234910277\n",
      "Validation: 0.4964539007092199\n",
      "-----\n",
      "Repeat = 0.25000000000000006\n",
      "F1 score\n",
      "Training: 0.7039390088945362\n",
      "Validation: 0.5288808664259929\n",
      "-----\n",
      "Repeat = 0.30000000000000004\n",
      "F1 score\n",
      "Training: 0.6515353805073432\n",
      "Validation: 0.5290581162324649\n",
      "-----\n",
      "Repeat = 0.3500000000000001\n",
      "F1 score\n",
      "Training: 0.5959221501390176\n",
      "Validation: 0.5269058295964126\n",
      "-----\n",
      "Repeat = 0.40000000000000013\n",
      "F1 score\n",
      "Training: 0.5717035611164581\n",
      "Validation: 0.5095693779904307\n",
      "-----\n",
      "Repeat = 0.45000000000000007\n",
      "F1 score\n",
      "Training: 0.5400885391047712\n",
      "Validation: 0.4961636828644502\n",
      "-----\n",
      "Repeat = 0.5000000000000001\n",
      "F1 score\n",
      "Training: 0.5111561866125761\n",
      "Validation: 0.49392712550607293\n",
      "-----\n",
      "Repeat = 0.5500000000000002\n",
      "F1 score\n",
      "Training: 0.4789915966386555\n",
      "Validation: 0.47108603667136806\n",
      "-----\n",
      "Repeat = 0.6000000000000002\n",
      "F1 score\n",
      "Training: 0.4492208490059108\n",
      "Validation: 0.43952802359882004\n",
      "-----\n",
      "Repeat = 0.6500000000000001\n",
      "F1 score\n",
      "Training: 0.42487616951018164\n",
      "Validation: 0.4164133738601824\n",
      "-----\n",
      "Repeat = 0.7000000000000002\n",
      "F1 score\n",
      "Training: 0.39233370913190524\n",
      "Validation: 0.40189873417721517\n",
      "-----\n",
      "Repeat = 0.7500000000000002\n",
      "F1 score\n",
      "Training: 0.3748558246828143\n",
      "Validation: 0.37623762376237624\n",
      "-----\n",
      "Repeat = 0.8000000000000002\n",
      "F1 score\n",
      "Training: 0.3539094650205762\n",
      "Validation: 0.357504215851602\n",
      "-----\n",
      "Repeat = 0.8500000000000002\n",
      "F1 score\n",
      "Training: 0.33273056057866185\n",
      "Validation: 0.3476764199655766\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "fraction = np.arange(0.1,0.9, 0.05)\n",
    "f1_class(feature_train, target_train, fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- F1 score of training and validation data of the downsampling data improved comapred to the unbalanced data\n",
    "- However, the F1 score of the validation data still did not satisfy the requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio between positive and negative class: **2:3**, fraction = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_downsampled, target_train_downsampled = downsample(feature_train, \n",
    "                                                                 target_train, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4521640091116173"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the ratio between 1 and 0 - need to be ~50%\n",
    "sum(target_train_downsampled == 1)/len(target_train_downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the models, tune hyperparameters to see if there is any improvement in model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DecisionTreeClassfier model\n",
    "- Create a loop to test different hyperparameters (max_depth): test from 1-50\n",
    "- Then choose the best model based on F1 score of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1 - F1 Score 0.4837476099426386\n",
      "max_depth: 2 - F1 Score 0.5116279069767442\n",
      "max_depth: 3 - F1 Score 0.5116279069767442\n",
      "max_depth: 4 - F1 Score 0.5625587958607714\n",
      "max_depth: 5 - F1 Score 0.5830845771144278\n",
      "max_depth: 6 - F1 Score 0.5856459330143541\n",
      "max_depth: 7 - F1 Score 0.5916919959473151\n",
      "max_depth: 8 - F1 Score 0.5586272640610105\n",
      "max_depth: 9 - F1 Score 0.5693730729701952\n",
      "max_depth: 10 - F1 Score 0.5515832482124617\n",
      "max_depth: 11 - F1 Score 0.5443668993020937\n",
      "max_depth: 12 - F1 Score 0.5248780487804878\n",
      "max_depth: 13 - F1 Score 0.5330739299610895\n",
      "max_depth: 14 - F1 Score 0.5228136882129277\n",
      "max_depth: 15 - F1 Score 0.5210384959713519\n",
      "max_depth: 16 - F1 Score 0.5163704396632367\n",
      "max_depth: 17 - F1 Score 0.5231910946196661\n",
      "max_depth: 18 - F1 Score 0.5185856754306437\n",
      "max_depth: 19 - F1 Score 0.5238970588235294\n",
      "max_depth: 20 - F1 Score 0.5181058495821727\n",
      "max_depth: 21 - F1 Score 0.5089605734767025\n",
      "max_depth: 22 - F1 Score 0.5054744525547444\n",
      "max_depth: 23 - F1 Score 0.5058295964125561\n",
      "max_depth: 24 - F1 Score 0.5104450499545867\n",
      "max_depth: 25 - F1 Score 0.5130513051305131\n",
      "max_depth: 26 - F1 Score 0.5130513051305131\n",
      "max_depth: 27 - F1 Score 0.5130513051305131\n",
      "max_depth: 28 - F1 Score 0.5130513051305131\n",
      "max_depth: 29 - F1 Score 0.5130513051305131\n",
      "max_depth: 30 - F1 Score 0.5130513051305131\n",
      "max_depth: 31 - F1 Score 0.5130513051305131\n",
      "max_depth: 32 - F1 Score 0.5130513051305131\n",
      "max_depth: 33 - F1 Score 0.5130513051305131\n",
      "max_depth: 34 - F1 Score 0.5130513051305131\n",
      "max_depth: 35 - F1 Score 0.5130513051305131\n",
      "max_depth: 36 - F1 Score 0.5130513051305131\n",
      "max_depth: 37 - F1 Score 0.5130513051305131\n",
      "max_depth: 38 - F1 Score 0.5130513051305131\n",
      "max_depth: 39 - F1 Score 0.5130513051305131\n",
      "max_depth: 40 - F1 Score 0.5130513051305131\n",
      "max_depth: 41 - F1 Score 0.5130513051305131\n",
      "max_depth: 42 - F1 Score 0.5130513051305131\n",
      "max_depth: 43 - F1 Score 0.5130513051305131\n",
      "max_depth: 44 - F1 Score 0.5130513051305131\n",
      "max_depth: 45 - F1 Score 0.5130513051305131\n",
      "max_depth: 46 - F1 Score 0.5130513051305131\n",
      "max_depth: 47 - F1 Score 0.5130513051305131\n",
      "max_depth: 48 - F1 Score 0.5130513051305131\n",
      "max_depth: 49 - F1 Score 0.5130513051305131\n"
     ]
    }
   ],
   "source": [
    "for depth in range (1,50, 1):\n",
    "    model1 = DecisionTreeClassifier(random_state=12, max_depth=depth)\n",
    "    model1.fit(feature_train_downsampled, target_train_downsampled)\n",
    "    prediction_val = model1.predict(feature_val)\n",
    "    print('max_depth:', depth, '- F1 Score', f1_score(target_val, prediction_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- Now F1 score of lower max_depth (1-3) of the DOWNSAMPLED data improved comapred to the unbalanced data\n",
    "- However in general F1 score did not improve compared to the unbalanced data\n",
    "- There is not any max_depth that can produce F1 score that satisfies the requirement\n",
    "### Therefore Decision Tree is not an optimal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RandomForestClassfier model\n",
    "- Create a loop to iterate through different max_depths of the model.\n",
    "- Then choose the best model based on F1 score of the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first fit a random forest with default parameters to get a baseline idea of the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6011049723756906"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=12)\n",
    "rf.fit(feature_train_downsampled, target_train_downsampled)\n",
    "target_pred = rf.predict(feature_val)\n",
    "f1 = f1_score(target_val, target_pred)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This F1 score satisfied the requirement. Let try different max_deptsh with n_estimators=100 to see if we can improve the score further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6547441629408842 0.5547263681592041\n",
      "2 0.7038745387453873 0.5646794150731158\n",
      "3 0.7130434782608696 0.5748898678414097\n",
      "4 0.7234042553191489 0.5782092772384034\n",
      "5 0.7403314917127073 0.59375\n",
      "6 0.772501130710086 0.6070640176600443\n",
      "7 0.7936936936936937 0.6335540838852097\n",
      "8 0.8318425760286225 0.6301969365426696\n",
      "9 0.8668758404303003 0.6338797814207651\n",
      "10 0.9077328646748684 0.6295081967213114\n",
      "11 0.9470486111111112 0.6237942122186495\n",
      "12 0.9778346121057119 0.6244725738396626\n",
      "13 0.9894291754756871 0.6223175965665235\n",
      "14 0.997896508203618 0.6207627118644068\n",
      "15 0.9987389659520807 0.6191489361702127\n",
      "16 0.9995800083998321 0.634453781512605\n",
      "17 0.9995800083998321 0.6226415094339621\n",
      "18 0.9995800083998321 0.6222222222222222\n",
      "19 0.9995800083998321 0.6264550264550264\n",
      "20 0.9995800083998321 0.6292372881355933\n"
     ]
    }
   ],
   "source": [
    "#Create a loop to iterate through different max_depth values\n",
    "for n in range(1,21,1): \n",
    "    model2 = RandomForestClassifier(max_depth=n, n_estimators=100, random_state=12)\n",
    "    model2.fit(feature_train_downsampled, target_train_downsampled)\n",
    "    prediction_train = model2.predict(feature_train_downsampled)\n",
    "    prediction_val = model2.predict(feature_val)\n",
    "    f1_train = f1_score(target_train_downsampled, prediction_train)\n",
    "    f1_val = f1_score(target_val,prediction_val)\n",
    "    print(n, f1_train, f1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- F1 score of Random Forest of the DOWNSAMPLED data improved a lot comapred to the unbalanced data\n",
    "- Models with max_depth = [5, 6, 7, ...,20] returned satisfied F1 score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion for the Downsampling approach\n",
    "- Generally, F1 score improved in the downsampled data compared to the unbalanced data\n",
    "- Random Forest Classifier seems to be the optimal model with the highest F1 score (also satisfied the requirement of this assignment, which is >= 0.59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary table of different models with different sampling approach and their F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model               | Unbalanced/Upsampling/Downsampling | Optimal   max_depth | Acceptable   max_depth       | n_estimators | F1_Score      |\n",
    "|---------------------|------------------------------------|---------------------|------------------------------|--------------|---------------|\n",
    "| Decision Tree       | Unbalanced                         | 8                   | 8                            | NA           | 0.600         |\n",
    "|                     | Upsampling: 4                      | Not satisfied       | Not satisfied                | NA           | Not satisfied |\n",
    "|                     | Upsampling: 3                      | 6                   | 5, 6, 7, 8, 9                | NA           | 0.598         |\n",
    "|                     | Downsamling: 0.2                   | Not satisfied       | Not satisfied                | NA           | Not satisfied |\n",
    "|                     | Downsamling: 0.3                   | 7                   | 6, 7                         | NA           | 0.592         |\n",
    "| Random Forest       | Unbalanced                         | 11                  | 11, 13, 14, 15, 16,   19, 20 | 100          |        0.599  |\n",
    "|                     | Upsampling: 4                      | 12                  | 3, ...,20                    | 100          | 0.658         |\n",
    "|                     | Upsampling: 3                      | 10                  | 2, 4, 5, ..., 20             | 100          | 0.655         |\n",
    "|                     | Downsamling: 0.2                   | 12                  | 12, 14, 18                   | 100          | 0.585         |\n",
    "|                     | Downsamling: 0.3                   | 9                   | 5, 6, ..., 20                | 100          | 0.634         |\n",
    "| Logistic Regression | Unbalanced                         | NA                  | NA                           | NA           | Not satisfied |\n",
    "|                     | Upsampling: 4                      | NA                  | NA                           | NA           | Not satisfied |\n",
    "|                     | Upsampling: 3                      | NA                  | NA                           | NA           | Not satisfied |\n",
    "|                     | Downsamling: 0.2                   | NA                  | NA                           | NA           | Not satisfied |\n",
    "|                     | Downsamling: 0.3                   | NA                  | NA                           | NA           | Not satisfied |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion of Step 3:\n",
    "- Random Forest returned satisfied F1 score for all approaches.\n",
    "- Logistic Regression returned unsatisfied F1 score for all approaches.\n",
    "- Decision Tree returned satisfied F1 score for the unbalanced data, upsampling with the ratio of positive and negative class of 2:3, and downsampling with the ratio of positive and negative class of 2:3\n",
    "- Upsampling with the ratio of positive and negative class of 2:3 returns high enough F1 score and more acceptable max_depths for both Decision Tree and Random Forest. F1 score in the Logistic Regression model for this approach did not satisfy the threshold, however it's higher than other approaches. Therefore I will choose this approach for the 3 models in the next step together with their optimal parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Check the quality of the model using the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the three models by comparing the accuracy score of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the selected model with their corresponding hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DecisionTreeClassifier(random_state=12, max_depth=6)\n",
    "model2 = RandomForestClassifier(random_state=12, max_depth=10, n_estimators=100)\n",
    "model3 = LogisticRegression(random_state=12, solver = 'liblinear')                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the 3 models into our upsampled training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsampling the training data\n",
    "feature_train_upsampled_3, target_train_upsampled_3 = upsample(feature_train, target_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(feature_train_upsampled_3, target_train_upsampled_3)\n",
    "model2.fit(feature_train_upsampled_3, target_train_upsampled_3)\n",
    "model3.fit(feature_train_upsampled_3, target_train_upsampled_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for the test set using 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_decisiontree = model1.predict(feature_test)\n",
    "\n",
    "prediction_test_randomforest = model2.predict(feature_test)\n",
    "\n",
    "prediction_test_logisticregression = model3.predict(feature_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate F1 score using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model : 0.5997952917093142\n",
      "Random Forest Model : 0.6257521058965102\n",
      "Logistic Regression Model : 0.5119170984455959\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Model\", \": \", end=\"\")\n",
    "print(f1_score(target_test, prediction_test_decisiontree))\n",
    "print(\"Random Forest Model\", \": \", end=\"\")\n",
    "print(f1_score(target_test, prediction_test_randomforest))\n",
    "print(\"Logistic Regression Model\", \": \", end=\"\")\n",
    "print(f1_score(target_test, prediction_test_logisticregression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check overfitness by comparing the accuracy score between train and test sets for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions using training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train_decisiontree = model1.predict(feature_train_upsampled_3)\n",
    "\n",
    "prediction_train_randomforest = model2.predict(feature_train_upsampled_3)\n",
    "\n",
    "prediction_train_logisticregression = model3.predict(feature_train_upsampled_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare F1 score of training and test set to see if there are warnings of overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model\n",
      "Training set: 0.741978021978022\n",
      "Test set: 0.5997952917093142\n",
      "Random Forest Model\n",
      "Training set: 0.8821226620269682\n",
      "Test set: 0.6257521058965102\n",
      "Logistic Regression Model\n",
      "Training set: 0.6215102974828375\n",
      "Test set: 0.5119170984455959\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Model')\n",
    "print('Training set:', f1_score(target_train_upsampled_3, prediction_train_decisiontree))\n",
    "print('Test set:', f1_score(target_test, prediction_test_decisiontree))\n",
    "      \n",
    "print('Random Forest Model')\n",
    "print('Training set:', f1_score(target_train_upsampled_3, prediction_train_randomforest))\n",
    "print('Test set:', f1_score(target_test, prediction_test_randomforest))    \n",
    "      \n",
    "print('Logistic Regression Model')\n",
    "print('Training set:', f1_score(target_train_upsampled_3, prediction_train_logisticregression))\n",
    "print('Test set:', f1_score(target_test, prediction_test_logisticregression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate AUC-ROC metric and compare it with F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "probabilities_test_dt = model1.predict_proba(feature_test)\n",
    "probabilities_one_test_dt = probabilities_test_dt[:, 1]\n",
    "auc_roc_dt = roc_auc_score(target_test, probabilities_one_test_dt)\n",
    "\n",
    "#Random Forest\n",
    "probabilities_test_rf = model2.predict_proba(feature_test)\n",
    "probabilities_one_test_rf = probabilities_test_rf[:, 1]\n",
    "auc_roc_rf = roc_auc_score(target_test, probabilities_one_test_rf)\n",
    "\n",
    "#Logistic Regression\n",
    "probabilities_test_lr = model3.predict_proba(feature_test)\n",
    "probabilities_one_test_lr = probabilities_test_lr[:, 1]\n",
    "auc_roc_lr = roc_auc_score(target_test, probabilities_one_test_lr)\n",
    "\n",
    "print(\"AUC - ROC\", \n",
    "      \"------------\",\n",
    "      \"Decision Tree: {}\".format(auc_roc_dt),\n",
    "      \"Random Forest: {}\".format(auc_roc_rf), \n",
    "      \"Logistic Regression: {}\".format(auc_roc_lr), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: Best model: Random Forest Model\n",
    "- Pro: It's F1 score and AUC-ROC is the highest, also satisfying the threshold for F1 score\n",
    "- Con: The discrepancy in F1 score between training data and set data might warn about overfitness. However, we need to further check whether when the error on the training data continues to decrease while the error on test starts to increase. This test is beyond this assignment. \n",
    "- AUC - ROC is higher than F1 score for all 3 models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
